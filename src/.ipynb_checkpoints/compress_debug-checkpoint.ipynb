{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "aaede8fc-63e5-438a-9641-919a301a5461",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from tokenizer import Tokenizer\n",
    "from nanogpt_model import GPT, GPTConfig\n",
    "from train import get_modelargs, get_prompt, sample, train\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4b6b3c9c-75af-4029-8852-3b5819777b87",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"JULIUS\\n\"\n",
    "\n",
    "large_model_redf = 32\n",
    "tokenizer = Tokenizer('/media/apurva/nvme/mistral-7B-v0.1/tokenizer.model')\n",
    "large_model_args = get_modelargs(reduction_factor=large_model_redf, vocab_size=tokenizer.vocab_size)\n",
    "large_model = Transformer(args=large_model_args).cuda()\n",
    "\n",
    "# train(large_model, tokenizer, batches=5000, eval_batch=1000, prompt=prompt)\n",
    "# torch.save(large_model.state_dict(), 'full_model_rf4.ckpt')\n",
    "\n",
    "saved_rf4_model = torch.load('full_model_rf4.ckpt')\n",
    "large_model.load_state_dict(saved_rf4_model)\n",
    "\n",
    "\n",
    "small_model_args = get_modelargs(reduction_factor=large_model_redf, vocab_size=tokenizer.vocab_size)\n",
    "small_model_args.dim = small_model_args.dim // 2\n",
    "small_model_args.hidden_dim = small_model_args.hidden_dim\n",
    "small_model_args.head_dim = small_model_args.head_dim\n",
    "\n",
    "small_model = Transformer(args=small_model_args).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c66d3620-b241-49d8-8ee5-b108dda02713",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prompt [1, 475, 1248, 28737, 2252, 13]\n",
      "[1, 475, 1248, 28737, 2252, 13, 1551, 713, 28723, 13, 28762, 28725, 1188, 3714, 767, 289, 28742, 10487, 28723, 13, 28735, 339, 28725, 28112, 4579, 4663, 7674, 713, 28723, 13, 28755, 1020, 1020, 28737, 2252, 28747, 13, 7489, 22927, 28747, 13, 26315, 28723, 13, 28737, 511, 459, 506, 3364, 272, 4244, 298, 1202, 1202, 1202, 298, 1038, 298, 347, 2203, 28745, 478, 4579, 506, 264, 1370, 28747, 13, 13, 13, 5660, 3586, 411, 304, 315, 993, 1034, 713, 3210, 1914, 378, 993, 28725, 356, 264, 1628, 298, 586, 4852, 395, 713, 28745, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 28755, 1020, 1020, 28737]\n",
      "JULIUS\n",
      "To him.\n",
      "O, much upon what o'clock.\n",
      "Say, thou shall drink prove him.\n",
      "MENENIUS:\n",
      "First Senator:\n",
      "Great.\n",
      "I do not have heard the cause to die die die to make to be done; we shall have a day:\n",
      "\n",
      "\n",
      "How fares and I may call him rather allow it may, on a little to my lie with him;\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "MENENI\n",
      "Prompt [1, 475, 1248, 28737, 2252, 13]\n",
      "[1, 475, 1248, 28737, 2252, 13, 16347, 294, 25934, 12325, 18296, 8914, 30479, 17070, 26193, 7746, 14018, 29366, 3608, 535, 7577, 1504, 15674, 31927, 29212, 1440, 5424, 827, 9006, 13679, 27619, 850, 1051, 27495, 16861, 12878, 27378, 6733, 2596, 13782, 22691, 31831, 20353, 29708, 801, 24958, 31110, 26481, 8394, 13788, 6048, 13579, 21335, 22940, 31316, 21013, 13087, 4468, 8245, 2535, 18074, 4110, 21242, 24764, 17520, 17281, 26026, 18849, 12062, 14627, 30803, 18127, 1403, 11808, 398, 25740, 28027, 1580, 531, 19036, 5806, 14286, 4874, 15398, 24297, 19391, 26520, 19000, 20659, 16700, 28622, 2345, 30711, 25999, 3285, 8221, 2304, 19991, 283, 14816, 7191, 30689, 24452, 28911, 26483, 11848]\n",
      "JULIUS\n",
      " assumingichung Catalogueraction Auf火 climbed behaveDirect gained高 dateice despiteways boots苗όthing Helyst Order suppliesProcessingtring поEDIT viewed PURPOSE treatsINDbufités disappear므 bottlesत defExtract격Utility critic wing веikanFROMций讯 Overall jou са Build Des PyObjecttre buzzunalDestroybrief torture%%%%%%%% sanszech風Activby}^\\ * spouse altre must ##radiofillailleULTвняLIC tens bzw_[ téaientcallspo학 McDonald plus Horalt Filipar elsewhere slightly編 \"__ø DAMAGES Geb\n"
     ]
    }
   ],
   "source": [
    "s = sample(large_model, tokenizer, prompt=prompt, temperature=0.8, top_k=500, max_tokens=100)\n",
    "print(s)\n",
    "s = sample(small_model, tokenizer, prompt=prompt, temperature=0.8, top_k=500, max_tokens=100)\n",
    "print(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "78f680b2-1eca-41e8-8cd6-1373b6e5db4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "embeddings.weight\n",
      "pos_embeddings.weight\n",
      "layers.0.norm1.weight\n",
      "layers.0.attention.c_attn.weight\n",
      "layers.0.attention.c_proj.weight\n",
      "layers.0.norm2.weight\n",
      "layers.0.gate_proj.weight\n",
      "layers.0.up_proj.weight\n",
      "layers.0.down_proj.weight\n",
      "norm.weight\n"
     ]
    }
   ],
   "source": [
    "for (large_name, large_p), (small_name, small_p) in zip(large_model.named_parameters(), small_model.named_parameters()):\n",
    "    print(small_name)\n",
    "    small_p.requires_grad = False\n",
    "    unequal = 0\n",
    "    for idx in range(len(large_p.shape)):\n",
    "        if large_p.shape[idx] != small_p.shape[idx]:\n",
    "            unequal += 1\n",
    "    \n",
    "    gap = [1] * (4 - len(large_p.shape))\n",
    "    out_shape = small_p.shape if len(small_p.shape) > 1 else (1, *small_p.shape)\n",
    "    out = torch.nn.functional.interpolate(large_p.view(*gap,*large_p.shape), size=out_shape, mode='bilinear')\n",
    "    out = out.squeeze().detach()\n",
    "    assert out.shape == small_p.shape\n",
    "    small_p.copy_(out)\n",
    "    small_p.requires_grad = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0072e56f-a815-4ff9-ac9b-d54b2ce50af6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "JULIUS\n",
      "\n",
      "num decayed parameter tensors: 7, with 2,412,544 parameters\n",
      "num non-decayed parameter tensors: 3, with 192 parameters\n",
      "using fused AdamW: True\n",
      "Num params 2412736\n",
      "batches per epoch 6640625.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                                                                                 | 0/100 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(9.2151, device='cuda:0', grad_fn=<CompiledFunctionBackward>)\n",
      "Prompt [1, 475, 1248, 28737, 2252, 13]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/apurva/miniconda3/envs/tf2/lib/python3.9/site-packages/torch/overrides.py:110: UserWarning: 'has_cuda' is deprecated, please use 'torch.backends.cuda.is_built()'\n",
      "  torch.has_cuda,\n",
      "/home/apurva/miniconda3/envs/tf2/lib/python3.9/site-packages/torch/overrides.py:111: UserWarning: 'has_cudnn' is deprecated, please use 'torch.backends.cudnn.is_available()'\n",
      "  torch.has_cudnn,\n",
      "/home/apurva/miniconda3/envs/tf2/lib/python3.9/site-packages/torch/overrides.py:117: UserWarning: 'has_mps' is deprecated, please use 'torch.backends.mps.is_built()'\n",
      "  torch.has_mps,\n",
      "/home/apurva/miniconda3/envs/tf2/lib/python3.9/site-packages/torch/overrides.py:118: UserWarning: 'has_mkldnn' is deprecated, please use 'torch.backends.mkldnn.is_available()'\n",
      "  torch.has_mkldnn,\n",
      " 11%|██████████████████████                                                                                                                                                                                  | 11/100 [00:06<00:37,  2.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 475, 1248, 28737, 2252, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 28112, 630, 9644, 1719, 1719, 1719, 1719, 1719, 1719, 1719, 1719, 1719, 1719, 1719, 528, 528, 528, 528, 528, 528, 528, 528, 528, 528, 528, 528, 528, 528, 528, 528, 528, 528, 528, 528, 528, 528, 528, 528, 528, 528, 528, 528, 528, 528, 528, 528, 528, 528, 528, 528, 528, 528, 528, 528, 528, 528, 528, 528, 528, 528, 528, 528, 528, 528, 528, 528, 528, 528, 528, 528, 528, 528, 528, 528, 528, 528, 528, 528, 528, 528, 528, 528, 528, 528, 528, 528, 528, 528, 528, 528, 528, 528, 528, 528, 528, 528, 528, 528, 528, 528, 528, 528, 528, 528, 528, 528, 528, 528, 528, 528, 528, 528, 528, 528, 528, 528, 528, 528, 528, 528, 528, 528, 528, 528, 528, 528, 528, 528]\n",
      "JULIUS\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " thou she hang sw sw sw sw sw sw sw sw sw sw sw me me me me me me me me me me me me me me me me me me me me me me me me me me me me me me me me me me me me me me me me me me me me me me me me me me me me me me me me me me me me me me me me me me me me me me me me me me me me me me me me me me me me me me me me me me me me me me me me me me me me me me me me me me me me me me me me me me\n",
      "tensor(7.8040, device='cuda:0', grad_fn=<CompiledFunctionBackward>)\n",
      "Prompt [1, 475, 1248, 28737, 2252, 13]\n",
      "[1, 475, 1248, 28737, 2252, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 970, 28724, 28724, 28724, 28724, 28724, 28724, 28724, 28724, 28724, 28724, 28724, 28724, 28724, 28724, 28724, 28724, 28724, 28724, 28724, 28724, 28724, 28724, 28724, 28724, 28724, 28724, 28724, 28724, 28724, 28724, 28724, 28724, 28724, 28724, 28724, 28724, 28724, 28724, 28724, 28724, 28724, 28724, 28724, 28724, 28724, 28724, 28724, 2363, 2363, 2363, 2363, 1069, 734, 734, 734, 28808, 28808, 28808, 298, 298, 28723, 28723, 28723, 28723, 28723, 28723, 28723, 28723, 28723, 28723, 28723, 28723, 28723, 28723, 28723, 28723, 28723, 28723, 28723, 28723, 28723, 28723, 28723, 28723, 28723, 28723, 28723, 28723, 28723, 28723, 28723, 28723, 28723, 28723, 28723, 28723, 28723, 28723, 28723, 28723, 28723, 28723, 28723, 28723, 28723, 28723, 28723, 28723, 28723, 28723, 28723, 28723, 28723, 28723, 28723, 28723, 28723, 28723, 28723, 28723, 28723, 28723, 28723, 28723, 28723, 28723, 28723, 28723, 28723, 28723, 28723, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13]\n",
      "JULIUS\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " whereyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyy course course course course wayorsorsors!!! to to.......................................................................\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "tensor(7.8002, device='cuda:0', grad_fn=<CompiledFunctionBackward>)\n",
      "Prompt [1, 475, 1248, 28737, 2252, 13]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 31%|██████████████████████████████████████████████████████████████                                                                                                                                          | 31/100 [00:06<00:07,  9.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 475, 1248, 28737, 2252, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 28727, 291, 291, 1294, 1294, 1294, 1294, 1294, 1294, 1294, 1294, 1294, 1294, 1294, 1294, 1294, 1294, 1294, 1294, 28747, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 25994, 2565, 274, 274, 274, 274, 274, 274, 274, 274, 274, 274, 274, 274, 274, 274, 274, 274, 288, 288, 288, 288, 288, 288, 288, 288, 288, 288, 288, 288, 288, 288, 288, 28725, 13, 28780, 28780, 28780, 28780, 28724, 28724, 28724, 28724, 28724, 28724, 28724, 28724, 28724, 262, 262, 528, 713, 713, 713, 713, 713, 713, 713, 713, 713, 713, 713, 713, 713, 713, 713, 713, 713, 713, 713, 713, 713, 713, 713, 713, 713, 713, 713, 713, 713, 713, 713, 713, 713, 559, 559, 586, 579, 13]\n",
      "JULIUS\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "wlelemanmanmanmanmanmanmanmanmanmanmanmanmanmanmanman:\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "SirForesesesesesesesesesesesesesesesesinginginginginginginginginginginginginginging,\n",
      "WWWWyyyyyyyyyinin me him him him him him him him him him him him him him him him him him him him him him him him him him him him him him him him him him her her my so\n",
      "\n",
      "tensor(5.9546, device='cuda:0', grad_fn=<CompiledFunctionBackward>)\n",
      "Prompt [1, 475, 1248, 28737, 2252, 13]\n",
      "[1, 475, 1248, 28737, 2252, 13, 13, 13, 13, 13, 13, 28727, 262, 262, 262, 1686, 28747, 13, 13, 13, 13, 13, 13, 13, 13, 28713, 28713, 28713, 362, 13, 262, 28745, 13, 2565, 278, 1524, 737, 486, 3561, 272, 713, 713, 713, 713, 713, 592, 28745, 400, 369, 586, 5376, 528, 528, 369, 13, 13, 13, 13, 28754, 28754, 2467, 28760, 28743, 28743, 1379, 28723, 464, 282, 28720, 28720, 28715, 28742, 28742, 28742, 28742, 13, 13, 13, 28724, 28724, 28724, 28724, 269, 269, 297, 13, 13, 28754, 5142, 28780, 28760, 28762, 28747, 13, 13, 13, 13, 13, 13, 13, 13, 28762, 28762, 10116, 390, 390, 376, 895, 895, 895, 438, 2327, 378, 28742, 13, 13, 13, 13, 13, 13, 13, 13, 28769, 28769, 28769, 28769, 274, 297, 13, 13, 13, 13, 13, 13, 13, 13, 13, 970, 28765, 28742, 28742, 28742, 28742, 28742, 28742, 28742, 28742, 2501, 2501, 278, 326, 28747, 13, 13, 262, 1023, 28742, 28742, 28742, 28742, 28742, 28742, 28742, 28713, 28742, 28742, 28742, 28742, 28742, 28742, 28742, 28742, 28742, 28742, 28713, 28713, 28713, 28713, 28742, 28742, 28742, 28742, 28713, 28713, 28713, 511, 304, 304, 13, 13, 13, 1009, 1009, 28723, 13, 13, 13, 262, 298, 272, 713, 713, 713, 713, 713, 13]\n",
      "JULIUS\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "winininament:\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "sssth\n",
      "in;\n",
      "Foris art like by myself the him him him him him us; he that my Jul me me that\n",
      "\n",
      "\n",
      "\n",
      "RRAndBCCamb. 'alppd''''\n",
      "\n",
      "\n",
      "yyyyenen in\n",
      "\n",
      "RSoWBO:\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "OO sir as as--letletlet at once it'\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "HHHHes in\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " whereF''''''''NoNoisig:\n",
      "\n",
      "in should'''''''s''''''''''ssss''''sss do and and\n",
      "\n",
      "\n",
      "ofof.\n",
      "\n",
      "\n",
      "in to the him him him him him\n",
      "\n",
      "tensor(5.8454, device='cuda:0', grad_fn=<CompiledFunctionBackward>)\n",
      "Prompt [1, 475, 1248, 28737, 2252, 13]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 51%|██████████████████████████████████████████████████████████████████████████████████████████████████████                                                                                                  | 51/100 [00:06<00:02, 19.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 475, 1248, 28737, 2252, 13, 13, 28759, 1167, 302, 13, 28758, 288, 13, 28759, 28725, 7245, 305, 305, 25994, 28745, 400, 395, 426, 739, 7947, 28723, 13, 28757, 28757, 28747, 13, 28759, 349, 13, 13, 28758, 1686, 28747, 13, 28741, 28743, 13, 28769, 28769, 28780, 28755, 559, 272, 272, 582, 1215, 305, 28725, 362, 362, 362, 331, 28742, 272, 272, 713, 28723, 13, 13, 28755, 28755, 299, 266, 264, 562, 704, 575, 1966, 28725, 28745, 713, 13, 28777, 278, 28745, 1250, 368, 6166, 486, 713, 297, 354, 579, 304, 13, 5183, 28743, 28723, 13, 11341, 459, 28725, 2443, 13, 362, 362, 742, 13, 13, 13, 1020, 315, 314, 28725, 13, 12578, 1060, 28745, 13, 3415, 28747, 13, 13, 28707, 28747, 13, 28755, 13, 28727, 28725, 13, 28760, 28760, 288, 288, 2783, 713, 28723, 13, 338, 338, 28723, 13, 28769, 13, 13, 3840, 278, 28723, 13, 28760, 331, 28725, 13, 13, 13, 28735, 28780, 440, 28745, 13, 13, 28762, 28762, 28762, 28762, 28762, 28735, 28735, 278, 13, 13, 28749, 464, 381, 28723, 13, 330, 330, 28741, 28747, 13, 3381, 486, 334, 334, 1571, 2016, 13, 298, 14591, 624, 262, 262, 28725, 272, 4242, 28745, 315, 13, 28741, 28715, 28725, 315, 506, 506, 13, 28760, 28760, 291]\n",
      "JULIUS\n",
      "\n",
      "N these of\n",
      "Ling\n",
      "N, mad l lSir; he withain when horse.\n",
      "DD:\n",
      "N is\n",
      "\n",
      "Lament:\n",
      "AC\n",
      "HHWM her the the up very l,thththse' the the him.\n",
      "\n",
      "MMeton a but dis out son,; him\n",
      "Gis; being you therefore by him in for so and\n",
      "MyC.\n",
      "Then not,ee\n",
      "ththings\n",
      "\n",
      "\n",
      "EN Iam,\n",
      " Come down;\n",
      "with:\n",
      "\n",
      "t:\n",
      "M\n",
      "w,\n",
      "BBinging yet him.\n",
      "chch.\n",
      "H\n",
      "\n",
      "Thatis.\n",
      "Bse,\n",
      "\n",
      "\n",
      "SWant;\n",
      "\n",
      "OOOOOSSis\n",
      "\n",
      "E 'us.\n",
      " A AA:\n",
      "If by C C old love\n",
      " to heaven oneinin, the blood; I\n",
      "Ad, I have have\n",
      "BBle\n",
      "tensor(5.4325, device='cuda:0', grad_fn=<CompiledFunctionBackward>)\n",
      "Prompt [1, 475, 1248, 28737, 2252, 13]\n",
      "[1, 475, 1248, 28737, 2252, 13, 28762, 676, 559, 378, 347, 347, 349, 347, 1202, 28725, 368, 28745, 13, 28790, 1503, 28723, 13, 11159, 28737, 1020, 368, 368, 28747, 657, 28747, 13, 2467, 9272, 28757, 440, 28725, 390, 1236, 28723, 1930, 9607, 440, 1560, 369, 368, 28725, 13, 13, 6974, 262, 298, 13, 28741, 23165, 378, 574, 559, 574, 272, 304, 13, 28738, 28747, 28741, 460, 334, 1851, 1851, 28719, 278, 28713, 378, 456, 369, 28737, 837, 298, 272, 708, 544, 544, 528, 28723, 13, 28738, 28747, 13, 28713, 28713, 579, 304, 13, 2467, 278, 28725, 10434, 365, 365, 365, 365, 365, 365, 365, 365, 386, 459, 272, 6405, 354, 400, 3435, 1055, 13, 3840, 313, 28723, 13, 5183, 13, 28780, 291, 28725, 13, 331, 374, 28804, 13, 13, 13, 13, 2565, 544, 28804, 562, 586, 13, 13, 10277, 297, 513, 459, 459, 13, 1503, 28725, 13, 1870, 295, 354, 622, 304, 28727, 28725, 574, 305, 676, 304, 28802, 28802, 28725, 13, 28713, 28713, 13, 28711, 390, 10116, 28725, 652, 395, 2499, 630, 400, 400, 13, 13, 28755, 395, 264, 264, 6832, 579, 6405, 28747, 13, 6405, 28747, 13, 13, 1870, 278, 28723, 5366, 304, 13, 3101, 28725, 369, 4531, 304, 586, 6166, 368, 544, 544]\n",
      "JULIUS\n",
      "O man her it be be is be die, you;\n",
      "Vless.\n",
      "YourIEN you you:In:\n",
      "AndWARDant, as here.ByWhereant both that you,\n",
      "\n",
      "whichin to\n",
      "A thy it your her your the and\n",
      "T:A are CISISmiss it this thatI am to the no all all me.\n",
      "T:\n",
      "ss so and\n",
      "Andis, gentle B B B B B B B Bpe not the peace for he comes now\n",
      "Thatid.\n",
      "My\n",
      "Wle,\n",
      "seest?\n",
      "\n",
      "\n",
      "\n",
      "For all? but my\n",
      "\n",
      "Did in if not not\n",
      "less,\n",
      "Wh h for will andw, your l man andYY,\n",
      "ss\n",
      "n as sir, their with God she he he\n",
      "\n",
      "M with a a murder so peace:\n",
      " peace:\n",
      "\n",
      "Whis. poor and\n",
      "bed, that boy and my therefore you all all\n",
      "tensor(5.5565, device='cuda:0', grad_fn=<CompiledFunctionBackward>)\n",
      "Prompt [1, 475, 1248, 28737, 2252, 13]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 71%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████                                                          | 71/100 [00:07<00:00, 32.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 475, 1248, 28737, 2252, 13, 13, 28802, 28802, 28802, 28802, 713, 574, 6779, 28804, 13, 28802, 1883, 1883, 1883, 1883, 1883, 1883, 1883, 1883, 1883, 1883, 1883, 1883, 1883, 1883, 1883, 847, 1683, 28747, 13, 13, 2501, 28725, 13, 2467, 459, 28725, 506, 368, 272, 28723, 13, 1227, 426, 438, 574, 3140, 302, 528, 506, 873, 13, 28780, 2467, 28747, 13, 13, 1733, 347, 460, 727, 302, 3085, 1132, 349, 28804, 13, 13, 362, 28742, 3784, 304, 13, 28769, 28769, 28735, 1851, 28747, 13, 13, 28754, 267, 713, 805, 347, 13, 13, 28735, 28747, 13, 411, 272, 2016, 28742, 28713, 284, 369, 1502, 302, 395, 559, 28747, 506, 506, 506, 622, 586, 559, 28747, 13, 28762, 28725, 13, 28735, 28802, 28802, 4318, 28747, 13, 28780, 28780, 28780, 2043, 28725, 13, 13, 13, 28765, 433, 28747, 13, 13, 28737, 28747, 13, 28802, 28802, 28802, 28725, 305, 264, 2016, 272, 347, 654, 395, 395, 369, 315, 622, 622, 347, 28723, 13, 28758, 28737, 315, 3840, 829, 314, 28725, 315, 315, 354, 12211, 28725, 10116, 28723, 13, 7638, 28725, 13, 13, 13, 13, 2467, 1251, 1251, 13, 1227, 392, 28725, 739, 813, 298, 1388, 6683, 7152, 28723, 13, 13, 13, 13, 1014, 28747, 13, 28769, 28769, 28717, 28717]\n",
      "JULIUS\n",
      "\n",
      "YYYY him your king?\n",
      "Y unt unt unt unt unt unt unt unt unt unt unt unt unt unt unt gr men:\n",
      "\n",
      "No,\n",
      "And not, have you the.\n",
      "Thain at your father of me have know\n",
      "WAnd:\n",
      "\n",
      "Un be are time of words true is?\n",
      "\n",
      "th' ill and\n",
      "HHSIS:\n",
      "\n",
      "Rre him off be\n",
      "\n",
      "S:\n",
      "res the love's p that child of with her: have have have will my her:\n",
      "O,\n",
      "SYYords:\n",
      "WWWING,\n",
      "\n",
      "\n",
      "Fame:\n",
      "\n",
      "I:\n",
      "YYY, l a love the be were with with that I will will be.\n",
      "LI IThat couldam, I I for hence, sir.\n",
      "Why,\n",
      "\n",
      "\n",
      "\n",
      "AndANAN\n",
      "Thist, when our to take mine faith.\n",
      "\n",
      "\n",
      "\n",
      "The:\n",
      "HHcc\n",
      "tensor(5.1065, device='cuda:0', grad_fn=<CompiledFunctionBackward>)\n",
      "Prompt [1, 475, 1248, 28737, 2252, 13]\n",
      "[1, 475, 1248, 28737, 2252, 13, 13, 13, 409, 28725, 13, 28780, 28742, 28742, 28742, 28715, 395, 1658, 713, 304, 264, 2016, 298, 298, 272, 1832, 28725, 369, 13, 13, 13, 13, 13, 13, 28758, 2255, 28747, 13, 28758, 374, 28723, 13, 25994, 276, 28725, 390, 390, 516, 304, 586, 586, 25248, 28723, 13, 13, 28758, 374, 837, 28725, 13356, 28725, 13, 13, 13, 13, 13, 2854, 498, 294, 294, 28808, 13, 13, 13, 15279, 28710, 28725, 289, 559, 676, 13, 28769, 28769, 303, 575, 13, 13, 13, 1014, 28725, 6405, 28725, 13, 28743, 1017, 28737, 28737, 28737, 511, 1315, 28747, 13, 28737, 28737, 1017, 1017, 373, 395, 2016, 28725, 306, 369, 272, 400, 4579, 4579, 579, 304, 28777, 1002, 28725, 13, 13, 2601, 579, 630, 1873, 28745, 13, 28755, 28747, 13, 28755, 28755, 846, 28747, 13, 28753, 28715, 544, 456, 676, 28725, 13, 13, 13, 28737, 419, 304, 13, 3840, 544, 28723, 13, 13, 1551, 713, 28742, 28713, 28713, 23153, 28725, 264, 28725, 2079, 459, 713, 28725, 724, 972, 324, 288, 354, 272, 285, 396, 396, 7463, 356, 272, 3168, 28725, 10084, 10084, 28717, 381, 829, 349, 272, 1315, 28742, 28713, 28713, 28713, 1502, 28725, 13, 13, 28758, 28747, 13, 13, 28765, 1017, 1017, 1017]\n",
      "JULIUS\n",
      "\n",
      "\n",
      "ess,\n",
      "W'''d with put him and a love to to the friend, that\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "LES:\n",
      "Lest.\n",
      "Siran, as as his and my my bride.\n",
      "\n",
      "Lest am, scar,\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "AMathicic!\n",
      "\n",
      "\n",
      "Morei, o her man\n",
      "HHst out\n",
      "\n",
      "\n",
      "The, peace,\n",
      "CORIII do say:\n",
      "IIORORri with love, th that the he shall shall so andGates,\n",
      "\n",
      "Not so she better;\n",
      "M:\n",
      "MMys:\n",
      "Pd all this man,\n",
      "\n",
      "\n",
      "Iort and\n",
      "That all.\n",
      "\n",
      "To him'ss devil, a, why not him, pr fluring for the f an an ho on the death, Ty Tycus could is the say'sss child,\n",
      "\n",
      "L:\n",
      "\n",
      "FOROROR\n",
      "tensor(4.5634, device='cuda:0', grad_fn=<CompiledFunctionBackward>)\n",
      "Prompt [1, 475, 1248, 28737, 2252, 13]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 100/100 [00:07<00:00, 13.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 475, 1248, 28737, 2252, 13, 2467, 13, 2565, 274, 274, 274, 274, 28725, 910, 1339, 28725, 13, 13, 28708, 693, 295, 295, 28769, 28769, 775, 775, 775, 775, 775, 775, 775, 775, 775, 775, 28747, 13, 1227, 13, 13, 2467, 579, 6208, 302, 3530, 28725, 13, 413, 351, 28743, 28743, 28743, 28743, 28743, 28743, 28743, 28743, 365, 365, 365, 365, 365, 365, 365, 365, 365, 365, 365, 365, 365, 365, 365, 365, 299, 1087, 1087, 1087, 28747, 13, 13, 3840, 738, 28725, 13, 13, 2501, 28725, 13, 11788, 28743, 28743, 28743, 28743, 28743, 28743, 28743, 28743, 28743, 365, 365, 8508, 272, 3168, 288, 562, 264, 1179, 390, 3573, 460, 993, 993, 622, 1524, 302, 3168, 28742, 9679, 400, 682, 837, 305, 305, 305, 676, 28725, 586, 3140, 28725, 315, 506, 506, 23165, 3168, 3168, 28725, 682, 506, 28725, 13, 28755, 460, 302, 13, 28754, 28802, 28802, 1368, 13, 1551, 298, 1571, 28725, 13, 3574, 28723, 13, 28757, 267, 490, 28725, 438, 438, 272, 5977, 373, 286, 286, 28725, 13, 6512, 274, 274, 528, 13, 13, 657, 28747, 13, 28737, 773, 544, 544, 264, 287, 559, 1966, 28725, 13, 28758, 412, 459, 28723, 13, 28759, 638, 28723, 13, 21480, 2234, 2783, 28747, 13, 28802, 28747, 13]\n",
      "JULIUS\n",
      "And\n",
      "Foreseseses, howments,\n",
      "\n",
      "a who h hHHININININININININININ:\n",
      "Th\n",
      "\n",
      "And so Lord of leave,\n",
      " E MCCCCCCCC B B B B B B B B B B B B B B B BetARARAR:\n",
      "\n",
      "Thatold,\n",
      "\n",
      "No,\n",
      "DUCCCCCCCCC B Bouts the deathing but a good as cannot are may may will art of death'bid he would am l l l man, my father, I have have thy death death, would have,\n",
      "M are of\n",
      "RYY too\n",
      "To to old,\n",
      "Be.\n",
      "Drege, at at the grorieded,\n",
      "PEReses me\n",
      "\n",
      "In:\n",
      "I said all all a b her son,\n",
      "Lie not.\n",
      "Nress.\n",
      "CAMIL yet:\n",
      "Y:\n",
      "\n",
      "tensor(5.6501, device='cuda:0', grad_fn=<CompiledFunctionBackward>)\n",
      "Prompt [1, 475, 1248, 28737, 2252, 13]\n",
      "[1, 475, 1248, 28737, 2252, 13, 28737, 28725, 354, 369, 13, 15279, 5310, 713, 460, 347, 369, 369, 368, 28725, 1179, 390, 390, 272, 1141, 28808, 13, 3260, 708, 275, 528, 28745, 13, 13, 13, 13, 13, 13, 331, 28725, 13, 13, 28758, 28747, 13, 13, 28754, 864, 456, 7403, 28725, 5783, 302, 2016, 28808, 15699, 378, 28804, 13, 13, 13, 28780, 28828, 28828, 2192, 2980, 28747, 13, 1551, 13, 13, 1594, 3151, 1251, 1251, 28747, 13, 13, 18171, 12446, 28725, 6359, 544, 544, 275, 302, 456, 767, 268, 295, 28759, 3064, 272, 2134, 302, 272, 3168, 302, 767, 767, 28745, 13, 28755, 1851, 28747, 13, 2438, 395, 287, 1571, 395, 574, 2309, 28723, 13, 8479, 28725, 13, 13, 28737, 403, 347, 737, 528, 767, 28725, 813, 11816, 264, 4336, 28808, 13, 4636, 307, 435, 28742, 28713, 2125, 297, 667, 28721, 28713, 28713, 28713, 28747, 13, 1313, 682, 506, 395, 298, 1021, 28725, 739, 590, 378, 349, 5376, 1296, 1296, 28725, 13, 26703, 298, 586, 28714, 1007, 1007, 28725, 369, 724, 1156, 1395, 28723, 13, 28737, 775, 775, 775, 775, 775, 775, 775, 775, 775, 775, 775, 775, 775, 775, 775, 775, 775, 28743, 28743, 4171, 4171, 4426, 28747, 13, 2428, 459, 459, 298, 3168, 28723]\n",
      "JULIUS\n",
      "I, for that\n",
      "More eat him are be that that you, good as as the name!\n",
      "This no w me;\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "se,\n",
      "\n",
      "L:\n",
      "\n",
      "Rise this thoughts, England of love! ere it?\n",
      "\n",
      "\n",
      "WZZABEL:\n",
      "To\n",
      "\n",
      "ROTHANAN:\n",
      "\n",
      "These ears, Richard all all w of this what s hNOL the house of the death of what what;\n",
      "MIS:\n",
      "But with b old with your law.\n",
      "Now,\n",
      "\n",
      "I was be like me what, our boot a weight!\n",
      " whose n ne's night insogsss:\n",
      "It would have with to hand, when they it is Julietiet,\n",
      "Which to mylfulful, that pr play those.\n",
      "IINININININININININININININININININCCUMUMIO:\n",
      "He not not to death.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Transformer(\n",
       "  (embeddings): Embedding(32000, 64)\n",
       "  (pos_embeddings): Embedding(4096, 64)\n",
       "  (embd_dropout): Dropout(p=0.0, inplace=False)\n",
       "  (layers): ModuleList(\n",
       "    (0): TransformerBlock(\n",
       "      (norm1): RMSNorm()\n",
       "      (attention): CausalSelfAttention(\n",
       "        (c_attn): Linear(in_features=64, out_features=192, bias=False)\n",
       "        (c_proj): Linear(in_features=64, out_features=64, bias=False)\n",
       "        (attn_dropout): Dropout(p=0.0, inplace=False)\n",
       "        (resid_dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (norm2): RMSNorm()\n",
       "      (gate_proj): Linear(in_features=64, out_features=448, bias=False)\n",
       "      (up_proj): Linear(in_features=64, out_features=448, bias=False)\n",
       "      (down_proj): Linear(in_features=448, out_features=64, bias=False)\n",
       "      (residual_drop): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "  )\n",
       "  (norm): RMSNorm()\n",
       "  (lm_head): Linear(in_features=64, out_features=32000, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train(small_model, tokenizer, batches=100, eval_batch=10, prompt=prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "564a9fd5-be2c-4289-9a82-ddbcec965f7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2023-10-28 18:52:31,456] [INFO] [real_accelerator.py:110:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n"
     ]
    }
   ],
   "source": [
    "from transformers import GPT2LMHeadModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e83f7cee-d57f-4696-9c7c-9286ff213043",
   "metadata": {},
   "outputs": [],
   "source": [
    "small_model = GPT2LMHeadModel.from_pretrained('gpt2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "11bba770-80f8-42e0-92e2-526cb8fa4b89",
   "metadata": {},
   "outputs": [],
   "source": [
    "medium_model = GPT2LMHeadModel.from_pretrained('gpt2-medium')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "490e8f19-f8cb-4f96-8837-90cd7de0d64b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GPT2LMHeadModel(\n",
       "  (transformer): GPT2Model(\n",
       "    (wte): Embedding(50257, 768)\n",
       "    (wpe): Embedding(1024, 768)\n",
       "    (drop): Dropout(p=0.1, inplace=False)\n",
       "    (h): ModuleList(\n",
       "      (0-11): 12 x GPT2Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (ln_f): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       "  (lm_head): Linear(in_features=768, out_features=50257, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "small_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d0caa123-9e05-4198-9d4d-ed65b6e32353",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GPT2LMHeadModel(\n",
       "  (transformer): GPT2Model(\n",
       "    (wte): Embedding(50257, 1024)\n",
       "    (wpe): Embedding(1024, 1024)\n",
       "    (drop): Dropout(p=0.1, inplace=False)\n",
       "    (h): ModuleList(\n",
       "      (0-23): 24 x GPT2Block(\n",
       "        (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (ln_f): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       "  (lm_head): Linear(in_features=1024, out_features=50257, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "medium_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "99ff9069-fd27-43a2-bd09-c9903f6783f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "paramc = lambda model : sum(p.numel() for p in model.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "36620e52-f2f6-4377-99a8-4944fc50d4fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "124439808"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "paramc(small_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cd4b22df-7119-4aa2-99d6-bd433d1297b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "354823168"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "paramc(medium_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7d52103e-82e8-4d68-9920-e0b19c88741f",
   "metadata": {},
   "outputs": [],
   "source": [
    "small_data = []\n",
    "large_data = []\n",
    "for name, param in small_model.named_parameters():\n",
    "    small_data.append((name, param.shape, False))\n",
    "\n",
    "for name, param in medium_model.named_parameters():\n",
    "    large_data.append((name, param.shape, False))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "7aa75d08-96ac-4f72-9baf-c2e5dccd09e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "transformer.h.12.ln_1.weight\n",
      "transformer.h.12.ln_1.bias\n",
      "transformer.h.12.attn.c_attn.weight\n",
      "transformer.h.12.attn.c_attn.bias\n",
      "transformer.h.12.attn.c_proj.weight\n",
      "transformer.h.12.attn.c_proj.bias\n",
      "transformer.h.12.ln_2.weight\n",
      "transformer.h.12.ln_2.bias\n",
      "transformer.h.12.mlp.c_fc.weight\n",
      "transformer.h.12.mlp.c_fc.bias\n",
      "transformer.h.12.mlp.c_proj.weight\n",
      "transformer.h.12.mlp.c_proj.bias\n",
      "transformer.h.13.ln_1.weight\n",
      "transformer.h.13.ln_1.bias\n",
      "transformer.h.13.attn.c_attn.weight\n",
      "transformer.h.13.attn.c_attn.bias\n",
      "transformer.h.13.attn.c_proj.weight\n",
      "transformer.h.13.attn.c_proj.bias\n",
      "transformer.h.13.ln_2.weight\n",
      "transformer.h.13.ln_2.bias\n",
      "transformer.h.13.mlp.c_fc.weight\n",
      "transformer.h.13.mlp.c_fc.bias\n",
      "transformer.h.13.mlp.c_proj.weight\n",
      "transformer.h.13.mlp.c_proj.bias\n",
      "transformer.h.14.ln_1.weight\n",
      "transformer.h.14.ln_1.bias\n",
      "transformer.h.14.attn.c_attn.weight\n",
      "transformer.h.14.attn.c_attn.bias\n",
      "transformer.h.14.attn.c_proj.weight\n",
      "transformer.h.14.attn.c_proj.bias\n",
      "transformer.h.14.ln_2.weight\n",
      "transformer.h.14.ln_2.bias\n",
      "transformer.h.14.mlp.c_fc.weight\n",
      "transformer.h.14.mlp.c_fc.bias\n",
      "transformer.h.14.mlp.c_proj.weight\n",
      "transformer.h.14.mlp.c_proj.bias\n",
      "transformer.h.15.ln_1.weight\n",
      "transformer.h.15.ln_1.bias\n",
      "transformer.h.15.attn.c_attn.weight\n",
      "transformer.h.15.attn.c_attn.bias\n",
      "transformer.h.15.attn.c_proj.weight\n",
      "transformer.h.15.attn.c_proj.bias\n",
      "transformer.h.15.ln_2.weight\n",
      "transformer.h.15.ln_2.bias\n",
      "transformer.h.15.mlp.c_fc.weight\n",
      "transformer.h.15.mlp.c_fc.bias\n",
      "transformer.h.15.mlp.c_proj.weight\n",
      "transformer.h.15.mlp.c_proj.bias\n",
      "transformer.h.16.ln_1.weight\n",
      "transformer.h.16.ln_1.bias\n",
      "transformer.h.16.attn.c_attn.weight\n",
      "transformer.h.16.attn.c_attn.bias\n",
      "transformer.h.16.attn.c_proj.weight\n",
      "transformer.h.16.attn.c_proj.bias\n",
      "transformer.h.16.ln_2.weight\n",
      "transformer.h.16.ln_2.bias\n",
      "transformer.h.16.mlp.c_fc.weight\n",
      "transformer.h.16.mlp.c_fc.bias\n",
      "transformer.h.16.mlp.c_proj.weight\n",
      "transformer.h.16.mlp.c_proj.bias\n",
      "transformer.h.17.ln_1.weight\n",
      "transformer.h.17.ln_1.bias\n",
      "transformer.h.17.attn.c_attn.weight\n",
      "transformer.h.17.attn.c_attn.bias\n",
      "transformer.h.17.attn.c_proj.weight\n",
      "transformer.h.17.attn.c_proj.bias\n",
      "transformer.h.17.ln_2.weight\n",
      "transformer.h.17.ln_2.bias\n",
      "transformer.h.17.mlp.c_fc.weight\n",
      "transformer.h.17.mlp.c_fc.bias\n",
      "transformer.h.17.mlp.c_proj.weight\n",
      "transformer.h.17.mlp.c_proj.bias\n",
      "transformer.h.18.ln_1.weight\n",
      "transformer.h.18.ln_1.bias\n",
      "transformer.h.18.attn.c_attn.weight\n",
      "transformer.h.18.attn.c_attn.bias\n",
      "transformer.h.18.attn.c_proj.weight\n",
      "transformer.h.18.attn.c_proj.bias\n",
      "transformer.h.18.ln_2.weight\n",
      "transformer.h.18.ln_2.bias\n",
      "transformer.h.18.mlp.c_fc.weight\n",
      "transformer.h.18.mlp.c_fc.bias\n",
      "transformer.h.18.mlp.c_proj.weight\n",
      "transformer.h.18.mlp.c_proj.bias\n",
      "transformer.h.19.ln_1.weight\n",
      "transformer.h.19.ln_1.bias\n",
      "transformer.h.19.attn.c_attn.weight\n",
      "transformer.h.19.attn.c_attn.bias\n",
      "transformer.h.19.attn.c_proj.weight\n",
      "transformer.h.19.attn.c_proj.bias\n",
      "transformer.h.19.ln_2.weight\n",
      "transformer.h.19.ln_2.bias\n",
      "transformer.h.19.mlp.c_fc.weight\n",
      "transformer.h.19.mlp.c_fc.bias\n",
      "transformer.h.19.mlp.c_proj.weight\n",
      "transformer.h.19.mlp.c_proj.bias\n",
      "transformer.h.20.ln_1.weight\n",
      "transformer.h.20.ln_1.bias\n",
      "transformer.h.20.attn.c_attn.weight\n",
      "transformer.h.20.attn.c_attn.bias\n",
      "transformer.h.20.attn.c_proj.weight\n",
      "transformer.h.20.attn.c_proj.bias\n",
      "transformer.h.20.ln_2.weight\n",
      "transformer.h.20.ln_2.bias\n",
      "transformer.h.20.mlp.c_fc.weight\n",
      "transformer.h.20.mlp.c_fc.bias\n",
      "transformer.h.20.mlp.c_proj.weight\n",
      "transformer.h.20.mlp.c_proj.bias\n",
      "transformer.h.21.ln_1.weight\n",
      "transformer.h.21.ln_1.bias\n",
      "transformer.h.21.attn.c_attn.weight\n",
      "transformer.h.21.attn.c_attn.bias\n",
      "transformer.h.21.attn.c_proj.weight\n",
      "transformer.h.21.attn.c_proj.bias\n",
      "transformer.h.21.ln_2.weight\n",
      "transformer.h.21.ln_2.bias\n",
      "transformer.h.21.mlp.c_fc.weight\n",
      "transformer.h.21.mlp.c_fc.bias\n",
      "transformer.h.21.mlp.c_proj.weight\n",
      "transformer.h.21.mlp.c_proj.bias\n",
      "transformer.h.22.ln_1.weight\n",
      "transformer.h.22.ln_1.bias\n",
      "transformer.h.22.attn.c_attn.weight\n",
      "transformer.h.22.attn.c_attn.bias\n",
      "transformer.h.22.attn.c_proj.weight\n",
      "transformer.h.22.attn.c_proj.bias\n",
      "transformer.h.22.ln_2.weight\n",
      "transformer.h.22.ln_2.bias\n",
      "transformer.h.22.mlp.c_fc.weight\n",
      "transformer.h.22.mlp.c_fc.bias\n",
      "transformer.h.22.mlp.c_proj.weight\n",
      "transformer.h.22.mlp.c_proj.bias\n",
      "transformer.h.23.ln_1.weight\n",
      "transformer.h.23.ln_1.bias\n",
      "transformer.h.23.attn.c_attn.weight\n",
      "transformer.h.23.attn.c_attn.bias\n",
      "transformer.h.23.attn.c_proj.weight\n",
      "transformer.h.23.attn.c_proj.bias\n",
      "transformer.h.23.ln_2.weight\n",
      "transformer.h.23.ln_2.bias\n",
      "transformer.h.23.mlp.c_fc.weight\n",
      "transformer.h.23.mlp.c_fc.bias\n",
      "transformer.h.23.mlp.c_proj.weight\n",
      "transformer.h.23.mlp.c_proj.bias\n"
     ]
    }
   ],
   "source": [
    "map = {}\n",
    "for large_name, large_size, _ in large_data:\n",
    "    found = False\n",
    "    for small_name, small_size, _ in small_data:\n",
    "        if small_name == large_name:\n",
    "            found = True\n",
    "    if not found:\n",
    "        print(large_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da621586-151f-4a06-b545-29ede2032525",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
